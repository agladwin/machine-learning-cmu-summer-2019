Facebook is embroiled in another vast privacy scandal. The company revealed on Tuesday that it had allowed Huawei and three other Chinese companies, in addition to Apple, Samsung and dozens of other device makers, access to data on Facebook users, their friends and their friends’ friends. These arrangements extended to data on religion, work and education history, and political preferences. Cambridge Analytica harvested the data of 87 million Facebook users; this latest scandal may affect many times that number of users. Sweeping privacy violations have the strange effect of revealing that the tracking of consumers by marketers affects everyone while hiding how that tracking hurts some people far more than others. People who value their privacy come from all demographic groups, but the impact of consumer tracking varies greatly by race, class and power. When you’re the “right” race, gender and sexual orientation, when you’ve got the right schools and jobs on your profile, marketers use tracking to flatter and include you. When you’re not, tracking is more likely to be used to exclude or exploit you. This disparate impact is a civil rights issue, and it should be treated like one by Congress. This problem predates Facebook. It’s apparent in marketing lists prepared by data brokers, the old guard in the consumer tracking industry. Lists of the wealthy use titles like “Established Elite” or “American Royalty” to highlight their strengths. The less fortunate are categorized by their vulnerabilities: “Ethnic Second-City Strugglers,” “Rural and Barely Making It” or “Hard Times,” a list made up of “an underclass of the working poor and destitute seniors without family support.” In one case, information from a data broker was used to defraud a 92-year-old Army veteran and steal his life savings. It’s one thing to receive junk mail or phone calls because you’re on one of those lists. But the sophisticated, real-time ad targeting developed by Facebook and other companies takes this marketing to another level. Tech companies can now target — or exclude — you entirely in secret, and often at the precise moment when you are most vulnerable. Facebook does not ask its users to identify their race. But the company figures it out anyway, monitoring users’ activity to tag them with ethnic “affinities.” As shown by two damning exposés, Facebook allowed housing advertisers to block users from seeing their ads if those users had a black, Latino or Asian-American “affinity.” Until recently, Google and Bing searches for “I need money for groceries” or “I need money for rent” would return prominent ads for predatory payday loans. Google blocked payday loan ads in 2016 under pressure from civil rights groups. Microsoft followed in 2017. While Facebook temporarily blocked “affinity marketing,” it’s unclear if it allows other discriminatory targeting. If you watched the royal wedding, you may have seen Amazon show off its new face-scanning software, Rekognition, by identifying celebrity wedding guests as they arrived at Windsor Castle. People are far more likely to encounter Rekognition when businesses and the police use it to secretly scan their faces to look for shoplifters. Poor people and people of color understand this distinction. Low-income adults, African-Americans and Latinos are significantly more likely than the wealthy and non-Hispanic whites to report being very concerned about what information is collected about them, or how it is used. More recently, after pressure from civil rights groups, Facebook is reportedly arranging for an outside auditor to study how its platform may harm underrepresented communities and people of color. Among the few available tools for vulnerable groups are the notices requiring personal consent before a company collects your sensitive data, which many have criticized as ineffective. It’s true that click-through consent screens, alone, are not enough to protect your privacy. But for Black Lives Matter protesters, victims of domestic violence and blue-collar retirees, the ability to click No is profoundly important. Congress needs to act. In other key areas of American economic life, from employment to housing to credit, Congress has built general protections for everyone — a minimum wage, mortgage insurance, disclosure rules for loans — but it has also recognized that those are not enough. Instead, in each of these areas, Congress has also seen it necessary to pass special protections for racial minorities and other vulnerable groups. Federal privacy law is blind to race. Legally, creating a list of Ethnic Second-City Strugglers is as innocuous as creating a list of people who like “PAW Patrol.” This is a mistake. The tracking of people’s race, religion, sexual orientation or health problems should be closely regulated, and in some cases banned. If you think this sounds extreme, consider that one data broker offered a list of “AIDS and H.I.V. Infection Sufferers” — 1,000 names for $79. The European Union’s new consumer privacy law creates protections for data that reveal those characteristics, along with information on a person’s membership in a labor union, a nod to the sensitivity of income and class. The European law thus implicitly recognizes that privacy is a matter of civil rights. The United States Congress should, too.